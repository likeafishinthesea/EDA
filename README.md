
# üìä Exploratory Data Analysis Projects

Welcome to my data analysis project repository! This repository features two Exploratory Data Analysis (EDA) projects where I explore and derive insights from datasets relevant to content engagement, user retention, and monetization strategies. These projects are designed to showcase my ability to perform EDA using both **Python (Pandas)** and **SQL**.

## üîç Project Overview

These two projects focus on understanding key aspects of digital publishing, including content engagement and user retention. Given the importance of data-driven decision-making in the media and publishing industry, these analyses can provide valuable insights to help optimize content strategy, improve user acquisition and retention, and increase monetization.

---

## Project 1: Content Engagement Analysis with Pandas üì∞

### **Objective**
This project explores user engagement across different types of content, such as articles, videos, and social media posts. The aim is to understand which content types drive the highest engagement and provide insights to optimize content strategy for an editorial team.

### **Data Source**
The dataset includes user interaction data such as views, clicks, time spent on content, and user engagement metrics. This data was either publicly available or simulated to reflect typical user behavior on digital publishing platforms.

### **Key Steps**
- **Data Cleaning and Preprocessing**: Performed with Pandas to handle missing data, duplicates, and format inconsistencies.
- **Descriptive Statistics**: Summarized key metrics like average time spent on content, total views, and user engagement rates.
- **Data Visualization**: Created visual representations of content engagement metrics, including bar charts and histograms, using Seaborn and Matplotlib.
- **Content Performance Analysis**: Grouped data by content type to analyze which categories led to higher user engagement.

### **Results & Insights**
- Discovered that **entertainment articles** had the highest engagement time on average, while **videos** were more effective in retaining users over time.
- Identified key performance indicators (KPIs) for tracking content success, such as average session duration and return user rate.

### **Technologies Used**
- **Python**: Pandas, Seaborn, Matplotlib
- **Jupyter Notebooks**

---

## Project 2: User Retention and Monetization Analysis with SQL üí∞

### **Objective**
This project focuses on analyzing user acquisition sources, retention rates, and monetization. By exploring relationships between acquisition channels and user engagement, we can identify key drivers of long-term retention and revenue.

### **Data Source**
The dataset contains user acquisition data (e.g., from organic search, social media, paid ads), user engagement metrics, and total revenue generated by each user. The data was structured to simulate a typical digital publishing platform.

### **Key Steps**
- **Data Structuring**: Built tables in an SQL database to store user acquisition and engagement data.
- **Retention Analysis**: Used SQL queries to calculate retention rates over time for different acquisition sources.
- **Monetization Insights**: Analyzed revenue data to identify which channels contributed most to long-term user monetization.
- **Performance Metrics**: Defined KPIs such as Customer Acquisition Cost (CAC), Lifetime Value (LTV), and retention rates to evaluate the effectiveness of various acquisition channels.

### **Results & Insights**
- Found that users acquired through **organic search** contributed the highest revenue per user but had lower retention compared to **social media** users, who were more likely to return over time.
- Proposed actionable steps for increasing retention by optimizing acquisition strategies and personalizing content based on user behavior.

### **Technologies Used**
- **SQL**: MySQL
- **BI Tools**: PowerBI (for visualization and reporting)

---

## üöÄ How to Run These Projects Locally

To explore the projects on your own machine, follow the steps below:

### 1. Clone the Repository
```
git clone https://github.com/yourusername/data-analysis-projects.git
cd data-analysis-projects
```

### 2. Python Project Setup (Pandas)
Make sure you have Python installed. You can create a virtual environment and install the necessary dependencies.

```
python -m venv venv
source venv/bin/activate  # On Windows use \`venv\Scriptsctivate\`
pip install -r requirements.txt
```

Then, launch the Jupyter notebook to explore the Pandas project.

```
jupyter notebook
```

### 3. SQL Project Setup
For the SQL project, ensure you have a working SQL database (e.g., MySQL, PostgreSQL). Import the provided \`.sql\` file to set up the database.

```sql
mysql -u username -p database_name < user_retention_analysis.sql
```

You can explore the SQL queries in the provided \`.sql\` file or run your own queries on the dataset.

---

## üõ†Ô∏è Tools & Technologies
- **Python (Pandas, Seaborn, Matplotlib)**: Used for data cleaning, manipulation, and visualization in the Content Engagement Analysis project.
- **SQL (MySQL/PostgreSQL)**: Used for querying and analyzing user acquisition, retention, and monetization data in the User Retention project.
- **Jupyter Notebooks**: For documenting the Python-based analysis and sharing interactive results.
- **PowerBI/Tableau**: For visualizing SQL query results in interactive dashboards.

---

## üë®‚Äçüíª About Me
I'm a data analyst with a passion for extracting insights from complex datasets to help businesses make data-driven decisions. In these projects, I focused on leveraging data to optimize content strategy, improve user retention, and enhance monetization strategies for digital publishing platforms.

Feel free to connect with me on [LinkedIn](#) or check out more of my work on [my website](#).

---

## ü§ù Contributing
If you‚Äôd like to contribute to these projects or have suggestions for improvements, feel free to fork the repository and submit a pull request!

---

## üìÑ License
These projects are licensed under the MIT License. See the `LICENSE` file for more information.

